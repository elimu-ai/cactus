/// Represents a single message in a chat conversation.
///
/// Used to construct the input for [CactusContext.completion] when performing
/// chat-based tasks.
class ChatMessage {
  /// The role of the entity sending the message.
  ///
  /// Common roles include:
  /// - `system`: Instructions or context for the AI model.
  /// - `user`: Input from the end-user.
  /// - `assistant`: Responses generated by the AI model.
  ///
  /// The specific roles supported may depend on the model and its training.
  final String role;

  /// The textual content of the message.
  final String content;

  /// Creates a new chat message.
  ///
  /// [role] is the role of the entity sending the message (e.g., 'system', 'user', 'assistant').
  /// [content] is the textual content of the message.
  ChatMessage({required this.role, required this.content});

  /// Converts the [ChatMessage] to a JSON-compatible map.
  ///
  /// This can be useful for serialization or logging.
  Map<String, String> toJson() => {
        'role': role,
        'content': content,
      };
}

/// The default ChatML template string used for formatting chat conversations
/// by the native `cactus` library if no custom template is provided during
/// [CactusContext.init] and if the model itself doesn't dictate a specific format.
///
/// ChatML is a simple markup language for structuring chat conversations.
/// This template structures messages with `<|im_start|>` and `<|im_end|>` tags,
/// differentiating between 'system', 'user', and 'assistant' roles.
/// It also includes a placeholder (`add_generation_prompt`) for indicating
/// where the assistant's response should begin.
///
/// **Note:** The actual prompt formatting is primarily handled by the native C++ layer.
/// This constant is provided for informational purposes and to understand the likely
/// default structure if no overrides are in place. The Dart-side prompt formatting
/// in [CactusContext.completion] provides a basic fallback if the native layer
/// expects a fully pre-formatted prompt and no chat_template was set at init.
const String defaultChatMLTemplate = """
{% for message in messages %}
  {% if message.role == 'system' %}
    {{ '<|im_start|>system\n' + message.content + '<|im_end|>\n' }}
  {% elif message.role == 'user' %}
    {{ '<|im_start|>user\n' + message.content + '<|im_end|>\n' }}
  {% elif message.role == 'assistant' %}
    {{ '<|im_start|>assistant\n' + message.content + '<|im_end|>\n' }}
  {% endif %}
{% endfor %}
{% if add_generation_prompt %}
  {{ '<|im_start|>assistant\n' }}
{% endif %}
""";